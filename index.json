[{"authors":"rawsanj","categories":null,"content":"I‚Äôm a Full-Stack Cloud Developer, currently working in JPMorgan Chase. My interests include Microservices, Server-less Architecture, Containers and I love building cool software and systems using Java, Kotlin, Node.js.\nI am AWS Certified Solutions Architect - Professional and I‚Äôve completed the Pivotal Platform Acceleration Labs program.\nIn this space, I intend to share my knowledge, Github projects and experience on all things cloud.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1644085312,"objectID":"46877d68f1bbddd7f5b0d5654e78d992","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I‚Äôm a Full-Stack Cloud Developer, currently working in JPMorgan Chase. My interests include Microservices, Server-less Architecture, Containers and I love building cool software and systems using Java, Kotlin, Node.js.\nI am AWS Certified Solutions Architect - Professional and I‚Äôve completed the Pivotal Platform Acceleration Labs program.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"AWS Lambda Filter Chain provides a way to add filters similar to javax.servlet.Filter to the AWS Lambda Functions handling requests from API Gateway\nInstallation Clone the Github repository $ git clone https://github.com/RawSanj/aws-lambda-filter-chain.git Build library and sample API Gateway Lambda Function $ ./build.sh Build \u0026amp; Run sample API Gateway Lambda Function locally $ ./build.sh runLocally Note: Install AWS SAM CLI and Docker to run aws lambda functions locally.\nTest the sample lambda function locally $ // Get All User $ curl http://127.0.0.1:3000/user $ // Post User $ curl -X POST http://localhost:3000/user -H \u0026#39;Accept: application/json\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;userName\u0026#34;: \u0026#34;john\u0026#34;,\u0026#34;fullName\u0026#34;: \u0026#34;John Doe\u0026#34;,\u0026#34;age\u0026#34;: 29,\u0026#34;company\u0026#34;: \u0026#34;Example\u0026#34;}\u0026#39; ","date":1556992173,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644085312,"objectID":"060dfaa472ac84c7d2dd01a72faadf85","permalink":"https://rawsanj.dev/project/aws-lambda-filter-chain/","publishdate":"2019-05-04T17:49:33Z","relpermalink":"/project/aws-lambda-filter-chain/","section":"project","summary":"AWS Lambda Filter Chain provides a way to add filters similar to javax.servlet.Filter to the AWS Lambda Functions handling requests from API Gateway","tags":["aws","lambda","java","annotation processing","reflection"],"title":"Aws Lambda Filter Chain","type":"project"},{"authors":null,"categories":null,"content":"Multi-instance Reactive Chat App using Spring Boot WebFlux and Redis Pub/Sub Scalable Java 11 Spring Boot WebFlux Chat Application to demonstrate use of Reactive Redis Pub/Sub using Reactive WebSocket Handler, without using any external Message Broker like RabbitMQ to sync messages between different instances.\nBoth JVM based application and Graal Native Image is supported.\nThe older non-reactive servlet based spring-redis-websocket application can be found in below links:\nSpring-Boot 2.3: Java-11 version Spring-Boot 1.5: Java-8 version The reactive spring-boot 2.4.6 based spring-redis-websocket application can be found in below:\nSpring-Boot 2.4.6: Java-11 Reactive JVM \u0026amp; Graal Native version Deploy to Play-with-Docker Ctrl + Click this button to deploy multiple instances of the spring-redis-websocket load balanced by NGINX:\nInstallation and Configuration Pre-requisite for Java Image: Install and run Redis locally or on Docker.\nTo run Redis in Docker:\n$ docker run -d -p 6379:6379 -e REDIS_PASSWORD=SuperSecretRedisPassword bitnami/redis:6.0.9 Pre-requisite for Graal Native Image: This application uses Spring Data Redis APIs which doesn‚Äôt have default Graal hints/config and graal-native image fails to run with errors.\nHence, this application is configured to use GraalVM native image tracing agent allows intercepting reflection, resources or proxy usage on the JVM by running simple Integration Tests which requires Redis.\nTo run integration test which uses Redis TestContainers so Docker should be configured properly to run Testcontainers You also need to install GraalVM JDK and native-image component: $ sdk install java 21.1.0.r11-grl # Using [SDKMAN](https://sdkman.io/jdks) install GraalVM distribution of JDK $ gu install native-image # Then install [native-image](https://www.graalvm.org/reference-manual/native-image) component Clone repo: $ git clone https://github.com/RawSanj/spring-redis-websocket.git Build and Run the application: Build and run the spring-redis-websocket application:\n$ cd spring-redis-websocket $ mvn clean package $ mvn spring-boot:run Build Graal Native Image of the application: Build and run the spring-redis-websocket native image:\n$ cd spring-redis-websocket $ mvn -Pnative clean package -DskipNativeImage=false $ target/spring-redis-websocket # run the executable binary Note: Above steps are applicable for Linux only and creates linux executable binary. To create Windows executable there are few additional set-ups required, follow this Steps.\nRun in Docker Build and run the spring-redis-websocket locally in Docker: Build the JAR file:\n$ mvn clean package Build Docker image:\n$ mvn clean spring-boot:build-image Build Graal Native Docker image:\n$ mvn -Pnative clean spring-boot:build-image Run docker image:\n$ docker run -d -p 8080:8080 rawsanj/spring-redis-websocket:2.5.2-webflux # JVM based Docker Image $ docker run -d -p 8080:8080 rawsanj/spring-redis-websocket:2.5.2-native # Graal Native Image based Docker Image Run multiple instances using docker-compose locally Run multiple instances of spring-redis-websocket locally load balanced via Ngnix connected to redis container in Docker:\n$ cd src/main/docker $ docker-compose up Or try Play with Docker to quickly setup Docker and run in browser: Click Create Instance to quickly setup Docker host. Install git by running: $ apk add git --no-cache Clone the repository: $ git clone https://github.com/RawSanj/spring-redis-websocket.git Run multiple instances of spring-redis-websocket: $ cd spring-redis-websocket/src/main/docker $ docker-compose up Run in Kubernetes Assuming you have a Kubernetes Cluster up and running locally: $ kubectl apply -f src/main/k8s Or try Play with Kubernetes to quickly setup a K8S cluster: Follow the instructions to create Kuberenetes cluster. Install git by running: $ yum install git -y Clone the repository: $ git clone https://github.com/RawSanj/spring-redis-websocket.git Run multiple instances of spring-redis-websocket load balanced by native Kubernetes Service. All instances connected to a single Redis pod. $ cd spring-redis-websocket $ kubectl apply -f src/main/k8s Tech spring-redis-websocket uses a number of open source projects:\nSpring Boot - An opinionated framework for building production-ready Spring applications. It favors convention over configuration and is designed to get you up and running as quickly as possible. Spring Data Redis - Spring Data Redis provides easy configuration and access to Redis from Spring applications. Graal Native Image - Native Image is a technology to ahead-of-time compile Java code to a standalone executable, called a native image. Redis - Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. Testcontainers - Testcontainers is a Java library that supports JUnit tests, providing lightweight, throwaway instances of common databases or anything else that can run in a Docker container. Bootstrap - Bootstrap is an open source ‚Ä¶","date":1552851570,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644096658,"objectID":"59bd0c63c6463d2e3d8e6277161e5eba","permalink":"https://rawsanj.dev/project/spring-redis-websocket/","publishdate":"2019-03-17T19:39:30Z","relpermalink":"/project/spring-redis-websocket/","section":"project","summary":"Multi-instance WebSocket messaging Chat App demo using Spring Boot and Redis Pub/Sub","tags":["spring-boot","redis","websocket","spring-data-redis","pub-sub","docker","docker-compose","kubernetes","ngnix","java"],"title":"Spring Redis Websocket","type":"project"},{"authors":null,"categories":null,"content":"Spring Cloud Task Application running as CronJob in Kubernetes A Spring Cloud Task Application which runs as CronJob in Kubernetes every minute to fetch BitCoin rates, saves the rates in Mysql and notifies Users if/when the threshold is reached.\nInstallation and Configuration Pre-requisite: MySql Server is up and running and application is configured the MySql credentials\nClone repo: $ git clone https://github.com/RawSanj/spring-cloud-task-as-k8s-cronjob.git Build and Run the applications: Build and run the spring-cloud-task-as-k8s-cronjob application:\n$ cd spring-cloud-task-as-k8s-cronjob $ mvn clean package $ mvn spring-boot:run Run in Kubernetes Assuming you have a Kubernetes Cluster up and running and kubectl is configured, run: $ kubectl apply -f src/main/k8s Or try Play with Kubernetes to quickly setup a K8S cluster: Follow the instructions to create Kubernetes cluster.\nInstall git by running:\n$ yum install git -y\nClone the repository:\n$ git clone https://github.com/RawSanj/spring-cloud-task-as-k8s-cronjob.git\nUpdate Kubernetes Secrets under src/main/k8s/cronjob.yaml file.\nRun spring-cloud-task-as-k8s-cronjob as Kubernetes CronJob. CronJob Pods connects to MySql server and stores Bitcoin rates every minute.\n$ cd spring-cloud-task-as-k8s-cronjob\n$ kubectl apply -f src/main/k8s\nClone and deploy the UI Application - spring-cronjob-currency by running kubectl apply -f src/main/k8s\n","date":1537126588,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644085312,"objectID":"a4a0fd0ae29ba15bd396c3684c61ce13","permalink":"https://rawsanj.dev/project/spring-cloud-task-as-k8s-cronjob/","publishdate":"2018-09-16T19:36:28Z","relpermalink":"/project/spring-cloud-task-as-k8s-cronjob/","section":"project","summary":"Spring Cloud Task Application running as CronJob in Kubernetes - Cron UI: [spring-cronjob-currency](https://github.com/RawSanj/spring-cronjob-currency)","tags":["spring-boot","spring-cloud-task","cronjob","kubernetes"],"title":"Spring Cloud Task as K8s Cronjob","type":"project"},{"authors":null,"categories":null,"content":"aws-service-broker is Open Service Broker compatible API server that provisions managed services in AWS.\nSupported AWS Services Amazon Relational Database Service (RDS) Amazon Simple Sorage Service (S3) Build, Test and Run Setup $ git clone https://github.com/RawSanj/aws-service-broker.git $ cd aws-service-broker Configuration: Create a new IAM user with Programmatic access (i.e. enable access key ID and secret access key for the AWS API) and attach following policies: AmazonRDSFullAccess, AmazonS3FullAccess and IAMFullAccess. Add the above noted AWS Access key, Secret key and export them as environment variable (AWS_ACCESS_KEY, AWS_SECRET_KEY and AWS_DEFAULT_REGION). Also Export Application Secret keys as environment variables. $ // Export AWS Keys $ export AWS_ACCESS_KEY=[YOUR_AWS_ACCESS_KEY] $ export AWS_SECRET_KEY=[YOUR_AWS_SECRET_KEY] $ export AWS_DEFAULT_REGION=[YOUR_AWS_DEFAULT_REGION] $ // Export Application Secret Keys $ export BROKER_APP_ADMIN_USERNAME=admin $ export BROKER_APP_ADMIN_PASSWORD=p@$$w0rd Build and Test $ mvn clean package Run the application: $ java -jar aws-service-broker-[version]-exec.jar ","date":1527964474,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644093087,"objectID":"150480e9f45d8b691a85ed213bb79e78","permalink":"https://rawsanj.dev/project/aws-service-broker/","publishdate":"2018-06-02T18:34:34Z","relpermalink":"/project/aws-service-broker/","section":"project","summary":"AWS Open Service Broker - Offering RDS and S3 Service","tags":["aws","kotlin","open-service-broker","cloudfoundry","kubernetes","spring-cloud","s3-bucket","rds-database"],"title":"Aws Service Broker","type":"project"},{"authors":null,"categories":null,"content":"AWS S3 as File System Application - Spring Cloud AWS - Spring Boot - Thymeleaf This is simple Spring Boot Application to upload/delete/search files in AWS S3 bucket. It uses Thymeleaf view tech and Bootstrap for responsive UI.\nIt also provides a REST api for creating Single Page Application using frameworks like Angular or React.\nTech aws-s3-file-system uses a number of open source projects:\nSpring Boot - An opinionated framework for building production-ready Spring applications. It favors convention over configuration and is designed to get you up and running as quickly as possible. Spring Cloud AWS - Spring Cloud for Amazon Web Services, eases the integration with hosted Amazon Web Services. It offers a convenient way to interact with AWS provided services using well-known Spring idioms and APIs. Thymeleaf - Thymeleaf is a modern server-side Java template engine for both web and standalone environments. Bootswatch - A Boostrap theme for great UI boilerplate for modern web apps. Installation and Configuration $ git clone https://github.com/RawSanj/aws-s3-file-system.git $ cd aws-s3-file-system Configuration:\nCreate a S3 bucket in Amazon Web Services. Create an IAM user with Programmatic access (i.e. enable access key ID and secret access key for the AWS API) and attach only AWS AmazonS3FullAccess policy. Add the above noted AWS Access key, Secret key and S3 Bucket name in /src/main/resources/application.properties file. Run the application:\n$ mvn clean package $ mvn spring-boot:run Run in Docker Build and run locally in Docker: Build the WAR file:\n$ mvn clean package Build docker image:\n$ mvn docker:build Run docker image by passing credentials in Environment variables:\n$ docker run -d -p 8080:8080 \\ $ -e cloud.aws.credentials.accessKey=ACCESS_KEY \\ $ -e cloud.aws.credentials.secretKey=SECRET_KEY \\ $ -e cloud.aws.region.static=REGION \\ $ -e aws.bucket.name=BUCKET_NAME \\ $ rawsanj/aws-s3-file-system Or Run docker image by updating the env.list file with AWS Credentials:\n$ docker run -d -p 8080:8080 --env-file env.list rawsanj/aws-s3-file-system Run on Cloud: Try http://play-with-docker.com for running docker on browser without any local setup.\nRun the docker image available in Docker Hub:\n$ docker run -d -p 8080:8080 \\ $ -e cloud.aws.credentials.accessKey=ACCESS_KEY \\ $ -e cloud.aws.credentials.secretKey=SECRET_KEY \\ $ -e cloud.aws.region.static=REGION \\ $ -e aws.bucket.name=BUCKET_NAME \\ $ rawsanj/aws-s3-file-system ","date":1524943142,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644085312,"objectID":"529a9abaff701cb2da541e86ccf417a9","permalink":"https://rawsanj.dev/project/aws-s3-file-system/","publishdate":"2018-04-28T19:19:02Z","relpermalink":"/project/aws-s3-file-system/","section":"project","summary":"AWS S3 File System Application","tags":["spring-cloud-aws","aws","spring-boot","thymeleaf","rest-api","aws-s3","spring-cloud","s3-bucket","bootswatch"],"title":"Aws S3 File System","type":"project"},{"authors":null,"categories":null,"content":"Spring Boot project for Kubeless Custom Runtime A simple Spring Boot Application to demonstrate how to build and run Custom Java Runtime on Kubeless for HTTP and Kafka Triggers.\nIt has two applications:\nboot-kubeless-http: A simple Spring Boot app for Kubeless HTTP trigger. It provides a GET and POST endpoint to add/list simple domain entity to demonstrate the use of various Spring projects. boot-kubeless-kafka: A simple Spring Boot app as Kafka Consumer for Kubeless Topic/Kafka trigger. Tech boot-kubeless uses a number of open source projects:\nSpring Boot - An opinionated framework for building production-ready Spring applications. It favors convention over configuration and is designed to get you up and running as quickly as possible. Kubeless - The Kubernetes Native Serverless Framework. Spring Data JPA - Spring Data JPA, part of the larger Spring Data family, makes it easy to easily implement JPA based repositories. Spring Boot Actuator - Actuator endpoints allow you to monitor and interact with your application. Spring for Kafka - The Spring for Apache Kafka project applies core Spring concepts to the development of Kafka-based messaging solutions. Installation and Configuration $ git clone https://github.com/RawSanj/boot-kubeless.git $ cd boot-kubeless Build and Run the applications: Build and run the boot-kubeless-http application:\n$ cd boot-kubeless-http $ mvn clean package $ mvn spring-boot:run Build and run the boot-kubeless-kafka application:\nNote: Download and Install Kafka. Set the Kafka Server Address and Topic name in application.yml file.\n$ cd boot-kubeless-kafka $ mvn clean package $ mvn spring-boot:run Run in Docker Build and run the boot-kubeless-http locally in Docker: Build the JAR file:\n$ cd boot-kubeless-http $ mvn clean package Build docker image:\n$ mvn docker:build Run docker image:\n$ docker run -d -p 8080:8080 \\ $ rawsanj/boot-kubeless-http Build and run the boot-kubeless-kafka locally in Docker: Build the JAR file:\n$ cd boot-kubeless-kafka $ mvn clean package Build docker image:\n$ mvn docker:build You would need to run Kafka in Docker. Try this Kafka docker image. Run docker image:\n$ docker run -d -p 8080:8080 \\ $ rawsanj/boot-kubeless-kafka --link \u0026lt;Kafka_Container\u0026gt;:alias Deploy on Kubernetes as FaaS using kubeless cli Setup and Install Kubeless. Follow the Steps here.\nDeploy the boot-kubeless-http as Kubeless Function with HTTP Trigger Deploy the Spring Boot app boot-kubeless-http as a Function using docker image available in Docker Hub:\n$ kubeless function deploy --runtime-image rawsanj/boot-kubeless-http --trigger-http boot-kubeless-http Test the function: Calls the GET method of Spring Boot App\n$ kubeless function call boot-kubeless-http Calls the POST method of Spring Boot App\n$ kubeless function call boot-kubeless-http --data \u0026#39;{\u0026#34;language\u0026#34;:\u0026#34;Go\u0026#34;,\u0026#34;rate\u0026#34;:1}\u0026#39; Deploy the boot-kubeless-kafka as Kubeless Function with Kafka/Topic Trigger Before deploying the function, lets create kafka topic:\n$ kubeless topic create boot-topic Deploy the Spring Boot app boot-kubeless-kafka as a Function using docker image available in Docker Hub:\n$ kubeless function deploy boot-kubeless-kafka --runtime-image rawsanj/boot-kubeless-kafka --trigger-topic boot-topic --env KUBELESS_KAFKA_SVC=kafka --env KUBELESS_KAFKA_NAMESPACE=kubeless Note: If you have your own Kafka Cluster running on K8S, update the namespace and service name in the environment variables above.\nTest the function: Publish message onto the Kafka topic\n$ kubeless topic publish --topic boot-topic --data \u0026#34;Hello From Kafka\u0026#34; Ssh into boot-kubeless-kafka Pods to check the Messages getting consumed.\n$ kubectl get pods | grep boot-kubeless-kafka // Note the Pod name. $ kubectl logs boot-kubeless-kafka-68b.... // Above pod name. You can also test the Function from Kubeless UI. ","date":1517597645,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644085312,"objectID":"c19f5be2d265f60076955c1db574c172","permalink":"https://rawsanj.dev/project/boot-kubeless/","publishdate":"2018-02-02T18:54:05Z","relpermalink":"/project/boot-kubeless/","section":"project","summary":"Spring Boot project for Custom Kubeless Runtime","tags":["spring-boot","kubernetes","faas","kubeless","kafka","spring-kafka"],"title":"Boot Kubeless","type":"project"},{"authors":null,"categories":null,"content":"Spring Boot - Spring Social Twitter - D3.Js webapp for Streaming Live #HashTags and source location of Tweets.\nDemo Live Demo @ Heroku PaaS.\nInstallation Clone the Github repository $ git clone https://github.com/RawSanj/Spring-Twitter-Stream.git Twitter App and Configuration Login to https://apps.twitter.com Create a New Application and note down the Consumer Key, Consumer Secret, Access Token and Access Token Secret. Edit the /src/main/resources/application.properties and add above noted keys. Run the application $ mvn spring-boot:run Then navigate to http://localhost:8080 in your browser.\nDeploy to Cloud Foundry Package the application (creates spring-twitter-stream-0.1.0.war file) $ mvn clean package Pre-requisite: Account @ http://run.pivotal.io. $87 Credit Free Account. cf cli is installed - http://docs.cloudfoundry.org/cf-cli Login to Pivotal Cloud Foundry $ cf login -a https://api.run.pivotal.io Deploy the application $ cf push spring-twitter-app -p target/spring-twitter-stream-0.1.0.war --random-route Deploy to Heroku Package the application (creates spring-twitter-stream-0.1.0.war file) $ mvn clean package Pre-requisite: Account @ https://www.heroku.com. Free Account. heroku cli is installed - https://devcenter.heroku.com/articles/heroku-cli Login to Heroku $ heroku login Install Heroku cli deploy plugin $ heroku plugins:install heroku-cli-deploy Create the application in Heroku $ heroku create spring-tweets-app Deploy the application $ heroku war:deploy target/spring-twitter-stream-0.1.0.war --app spring-tweets-app ","date":1515003712,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644085312,"objectID":"f69c4e61e7ab9f289eaee0fedb620e2a","permalink":"https://rawsanj.dev/project/spring-twitter-stream/","publishdate":"2018-01-03T18:21:52Z","relpermalink":"/project/spring-twitter-stream/","section":"project","summary":"Spring Boot - Spring Social - Twitter Stream with Word Cloud and Tweet Search","tags":["spring-twitter-stream","spring-social","thymeleaf","d3js","spring-boot"],"title":"Spring Twitter Stream","type":"project"},{"authors":null,"categories":null,"content":"This demo is created to test the Java Mail Clients, to configure MailService is jHipster application as suggested in jHipster Tip - Configuring Email with - Gmail Note (for Gmail) You must allow your Gmail Account to access less secure apps.\nLogin to Gmail and visit Here to Turn On Access for less secure apps.\nMore Info here\nInstallation $ git clone https://github.com/RawSanj/java-mail-clients.git Updated Version (added support for Attachments): Update ConfigConsts.java file with to and from Email address and password. Select the SMTP Server (GMAIL, YAHOO, OUTLOOK or ZOHO) and update the File path where the attachments are located. Run the SendEmailWithAttachments class as Java Application. Older Version: Change the sendToAddress, sendFromAddress and password in the respective E-Mail client app and run as Java Application. Reference Refer below links for API and SMTP settings:\nJavaMail API - JavaMail : version-1.5.4 GMail SMTP - Gmail SMTP Settings. Outlook SMTP - Outlook SMTP Settings. Yahoo SMTP - Yahoo SMTP Settings. Zoho SMTP - Zoho SMTP Settings. ","date":1508352562,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644093087,"objectID":"6b5bb945df85d5257f290c5acdbb8c08","permalink":"https://rawsanj.dev/project/java-mail-clients/","publishdate":"2017-10-18T18:49:22Z","relpermalink":"/project/java-mail-clients/","section":"project","summary":"Send Java Email from GMail, Outlook, Yahoo and Zoho. Demo App to test jHipster tip for Email","tags":["jhipster","smtp-settings","gmail-smtp","zoho-smtp","outlook-smtp","yahoo-smtp","javamail-api"],"title":"Java Mail Clients","type":"project"},{"authors":[],"categories":null,"content":"Docker Deep Dive for Java Developers Deep dive into Docker and Linux Containers Dockerfile Run Docker Containers Run Tomcat inside Docker Container Deploy Spring Boot App in Docker Container Linking and Stateful containers Play with Docker online ","date":1502713825,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644085312,"objectID":"8384eb2cc8460e91be9bb76075fd9062","permalink":"https://rawsanj.dev/talk/docker-deep-dive/","publishdate":"2017-08-14T12:30:25Z","relpermalink":"/talk/docker-deep-dive/","section":"talk","summary":"Docker Deep Dive for Java Developers","tags":["Docker","Container","LXC","Linux","Spring-Boot","Play-with-Docker"],"title":"Docker Deep Dive","type":"talk"},{"authors":[],"categories":null,"content":"Kubernetes for Java Developers Quick Intro to Docker Intro to Kubernetes Concepts Fabric8 - PaaS for K8s CI/CD in K8s using Fabric8 Play with Kubernetes online Shout-out to Stackpoint.io for making super easy to deploy Kubernetes back in 2016 ","date":1489494625,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644085312,"objectID":"e70ec0bece703c7983a4d81af179efdf","permalink":"https://rawsanj.dev/talk/intro-to-kubernetes/","publishdate":"2017-03-14T12:30:25Z","relpermalink":"/talk/intro-to-kubernetes/","section":"talk","summary":"Kubernetes for Java Developers","tags":["Kubernetes","Docker","Fabric8","Spring","CI/CD"],"title":"Intro to Kubernetes","type":"talk"},{"authors":null,"categories":null,"content":"Spring Boot - Batch project to read Movies from TheMovieDB REST API. Tech SpringRestBatch uses a number of open source projects:\nSpring Boot - Takes an opinionated view of building production-ready Spring applications. Spring Boot favors convention over configuration and is designed to get you up and running as quickly as possible. Spring Data JPA - Spring Data JPA, part of the larger Spring Data family, makes it easy to easily implement JPA based repositories. Spring Batch - A lightweight, comprehensive batch framework designed to enable the development of robust batch applications vital for the daily operations of enterprise systems. Installation Clone this repository by running below command: $ git clone https://github.com/RawSanj/SpringRestBatch.git Register @ https://www.themoviedb.org/documentation/api and get your API key. Update the REST_API_URL_WITH_KEY key in src/main/resources/application.properties file with your obtained key.\nStart your local PostgreSQL database, configure the database properties in src/main/resources/application.properties file.\nRun this application using embedded Tomcat and PostgreSql DB Server:\nmvn spring-boot:run ","date":1481137991,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644085312,"objectID":"6f6e05ce70102cba013910aecded0358","permalink":"https://rawsanj.dev/project/spring-rest-batch/","publishdate":"2016-12-07T19:13:11Z","relpermalink":"/project/spring-rest-batch/","section":"project","summary":"Spring Boot-Batch project to read Movies from [TheMovieDB](https://developers.themoviedb.org/3) REST API and store into database.","tags":["spring-data-jpa","spring-boot","spring-batch","themoviedb"],"title":"Spring Rest Batch","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644085312,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://rawsanj.dev/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":[""],"categories":null,"content":" AWS Lambda Deep Dive Documentation Hi there, I‚Äôm Sanjay üëã!\nAbout me üî≠ Working: Cloud Developer working on Reactive Spring Boot, Kafka, Cassandra, Microservices, AWS. üñ•Ô∏è Interests: I love building cool software and systems using Spring Boot, Kotlin and Go üå± Learning: Go | Scala | Design Patterns üí¨ Ask me about: Java | Reactive Spring | AWS üßë‚Äçü§ù‚Äçüßë Collaboration: I\u0026#39;m looking to collaborate on several projects over here, please check out my GitHub repos Languages, Frameworks and Platforms What is AWS Lambda Function A Compute Service to run code without Provisioning or Managing Servers Uses Containerization tech called Firecracker Handles Server \u0026amp; OS Maintenance, Provisioning, Auto-Scaling, Logging Code in one of the Languages supported by Lambda Runtimes Lambda Concepts Function: a resource invoked to run your code Trigger: a resource/config that invokes a Lambda Function Event: a JSON-formatted data for a Lambda Function to Process Event Source Mapping: a resource that reads items from a Stream/Queue \u0026amp; invokes a function Execution Env: provides a secure and isolated Runtime Environment for your Lambda function Runtime: provides a lang-specific Environment that runs in an Execution Environment What is Lambda Runtimes Runtime provides a lang-specific env that runs in an execution env It relays invocation Events, Context, \u0026amp; Responses between Lambda \u0026amp; the Function Use AWS provided Lambda Runtimes or Build your own by implementing Runtime API Execution Environment \u0026amp; Runtime Supported Lambda Runtimes Node.js v18, v16, v14 \u0026amp; v12* Python v3.9, v3.8, v3.7 Java v8, v11 C# .NET v5, v6 \u0026amp; .NET Core v3.1 Go v1.x Ruby v2.7* Custom Runtime - Based on Amazon Linux Micronaut Custom Runtime Implementation Example\nLambda Function Java public class MsgHandler implements RequestHandler\u0026lt;String, String\u0026gt; { public String handleRequest(String input, Context ctx) { context.getLogger().log(\u0026#34;Input: \u0026#34; + input); return \u0026#34;Hello World - \u0026#34; + input; } } public class StreamHandler implements RequestStreamHandler { public void handleRequest(InputStream is, OutputStream os, Context ctx) { String input = IOUtils.toString(is, \u0026#34;UTF-8\u0026#34;); os.write((\u0026#34;Hello World - \u0026#34; + input).getBytes()); } } public class NoInterfaceHandler { public String customHandle(String input, Context context) { context.getLogger().log(\u0026#34;Input: \u0026#34; + input); return \u0026#34;Hello World - \u0026#34; + input; } } Features Automatically manages the underlying Compute Resources Concurrency and Scaling controls Pay Per Request Execution is millis Multiple Event Sources: API-GW, SQS, S3, DynamoDB, etc. Functions defined as Container Images Lambda Extensions Execute inside Private Subnets inside a VPC File Systems Access + EFS Limitations Memory: 128 MB to 10,240 MB No Direct Way to assign CPU: 1,769 MB memory is equivalent of one vCPU Function Timeouts: 15 minutes Invocation Payload: 6 MB (sync) \u0026amp; 256 KB (async) File descriptors: 1024 Execution processes/threads: 1024 No Async Processing Allowed: Lambda Instance Freezes once invocation is completed 1 Lambda Instance serves only 1 request at time Other Compute Options Services Comparison with Lambda AWS EC2 Not Serverless, More RAM/CPU/Storage, Always ON AWS EKS Managed Container Platform on EC2 Fargate Serverless Container Platform on EC2 Beanstalk AWS Container based PaaS GCP Cloud RUN Based on OSS Knative - Charged for Runtime only Questions? ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681977600,"objectID":"25b41d6107640ce8f82fadaa16bcf181","permalink":"https://rawsanj.dev/slides/aws-lambda/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/aws-lambda/","section":"slides","summary":"A Deep Dive into AWS Lambda Function and Compute Options","tags":["aws","lambda","java","container"],"title":"AWS Lambda Deep Dive","type":"slides"},{"authors":[""],"categories":null,"content":" AWS SQS Lambda Integration with Resiliency Patterns Documentation Hi there, I‚Äôm Sanjay üëã!\nAbout me üî≠ Working: Cloud Developer working on Reactive Spring Boot, Kafka, Cassandra, Microservices, AWS. üñ•Ô∏è Interests: I love building cool software and systems using Spring Boot, Kotlin and Go üå± Learning: Go | Scala | Design Patterns üí¨ Ask me about: Java | Reactive Spring | AWS üßë‚Äçü§ù‚Äçüßë Collaboration: I\u0026#39;m looking to collaborate on several projects over here, please check out my GitHub repos Languages, Frameworks and Platforms What is AWS SQS SQS offers a Secure, Durable, and Highly Available Hosted Queue Used to integrate and decouple distributed software systems and components Standard queues support at-least-once message delivery, and FIFO queues support exactly-once message processing and high-throughput mode Offers Dead Letter Queues SQS Concepts w.r.t Lambda Queue Types: Standard and FIFO Visibility timeout: wait time after which message is visible again if not deleted after processing Message retention period: 1 minute to 14 days (defaults to 4 days) Delivery delay: 0 seconds to 15 minutes SQS Event Source Mapping: Lambda Service reads items from a SQS \u0026amp; invokes Lambda Function Enable trigger: Enable or disable SQS-Lambda Integration Batch size: number of records to send to the function in each batch. Standard: 10,000(max). FIFO: 10(max) Batch window: wait time (in second) to gather records before invoking the function, applicable for Standard Message Lifecycle SQS Visibility Timeout To avoid message loss, it\u0026#39;s consumers responsibility to delete the message after processing Message remains in queue after it is received, but SQS sets a visibility timeout to prevent other consumer from processing same message again Default visibility timeout is 30 seconds. Can be set between 0 seconds to 12 hours Can be set a Queue level or dynamically changed per message Caution: When using FIFO make sure to use Message GroupId which provides high distribution to avoid blocking processing due to error Note: For Standard queues, the visibility timeout isn\u0026#39;t a guarantee against receiving a message twice. FIFO queues allow the producer or consumer to attempt multiple retries: producers can retry send using deduplicationId and consumers doesn\u0026#39;t receive messages for same message groupId unless deleted or timed-out In-Flight Messages \u0026amp; Scaling Messages that are received by the consumer but not deleted are known as In-Flight messages For Standard queues: there can be a maximum of approximately 120,000 in flight messages For FIFO queues: there can be a maximum of 20,000 in flight messages Standard Queues: Lambda uses long polling \u0026amp; reads up to 5 batches to invoke your function. Lambda increases the number of processes that reads batches by up to 60 more instances per minute. The max no. of batches that an Event Source Mapping can process simultaneously is 1,000. FIFO queues: Lambda sends messages to your function in the order that it receives them and ensures that messages in the same group are delivered to Lambda in order. Lambda sorts the messages into groups and sends only one batch at a time for a group. Your function can scale in concurrency to the number of active message groups. SQS Message Event in Lambda Function - Standard { \u0026#34;Records\u0026#34;: [ { \u0026#34;messageId\u0026#34;: \u0026#34;059f36b4-87a3-44ab-83d2-661975830a7d\u0026#34;, \u0026#34;receiptHandle\u0026#34;: \u0026#34;AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Test message.\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;ApproximateReceiveCount\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;SentTimestamp\u0026#34;: \u0026#34;1545082649183\u0026#34;, \u0026#34;SenderId\u0026#34;: \u0026#34;AIDAIENQZJOLO23YVJ4VO\u0026#34;, \u0026#34;ApproximateFirstReceiveTimestamp\u0026#34;: \u0026#34;1545082649185\u0026#34; }, \u0026#34;messageAttributes\u0026#34;: {}, \u0026#34;md5OfBody\u0026#34;: \u0026#34;e4e68fb7bd0e697a0ae8f1bb342846b3\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;aws:sqs\u0026#34;, \u0026#34;eventSourceARN\u0026#34;: \u0026#34;arn:aws:sqs:us-east-2:123456789012:my-queue\u0026#34;, \u0026#34;awsRegion\u0026#34;: \u0026#34;us-east-2\u0026#34; }, ... ] } SQS Message Event in Lambda Function - FIFO { \u0026#34;Records\u0026#34;: [ { \u0026#34;messageId\u0026#34;: \u0026#34;11d6ee51-4cc7-4302-9e22-7cd8afdaadf5\u0026#34;, \u0026#34;receiptHandle\u0026#34;: \u0026#34;AQEBBX8nesZEXmkhsmZeyIE8iQAMig7qw...\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Test message.\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;ApproximateReceiveCount\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;SentTimestamp\u0026#34;: \u0026#34;1573251510774\u0026#34;, \u0026#34;SequenceNumber\u0026#34;: \u0026#34;18849496460467696128\u0026#34;, \u0026#34;MessageGroupId\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;SenderId\u0026#34;: \u0026#34;AIDAIO23YVJENQZJOL4VO\u0026#34;, \u0026#34;MessageDeduplicationId\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;ApproximateFirstReceiveTimestamp\u0026#34;: \u0026#34;1573251510774\u0026#34; }, \u0026#34;messageAttributes\u0026#34;: {}, \u0026#34;md5OfBody\u0026#34;: \u0026#34;e4e68fb7bd0e697a0ae8f1bb342846b3\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;aws:sqs\u0026#34;, \u0026#34;eventSourceARN\u0026#34;: \u0026#34;arn:aws:sqs:us-east-2:123456789012:fifo.fifo\u0026#34;, \u0026#34;awsRegion\u0026#34;: \u0026#34;us-east-2\u0026#34; } ] } SQS Resiliency Pattern with Lambda Enable Batch Error Reporting by running: aws lambda update-event-source-mapping \\ --uuid \u0026#34;a1b2c3d4-5678-90ab-cdef-123401\u0026#34; \\ --function-response-types \u0026#34;ReportBatchItemFailures\u0026#34; Update your Lambda Function code to collect messageId of failed messages: { \u0026#34;batchItemFailures\u0026#34;: [ { \u0026#34;itemIdentifier\u0026#34;: \u0026#34;message-id-1\u0026#34; }, { \u0026#34;itemIdentifier\u0026#34;: \u0026#34;message-id-4\u0026#34; } ] } Blog Post on Batch Error Reporting by srcecde\nCode Questions? ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681978547,"objectID":"b51fc5dc259ba2f87771423da86cd5c7","permalink":"https://rawsanj.dev/slides/aws-sqs-lambda-integration/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/aws-sqs-lambda-integration/","section":"slides","summary":"A Deep Dive into AWS SQS and Lambda Function Integration with Resiliency Patterns","tags":["aws","lambda","sqs","java","container","resiliency"],"title":"AWS SQS + Lambda Integration","type":"slides"},{"authors":[""],"categories":null,"content":" Blazing Fast Cost Effective \u0026amp; Resilient AWS SQS Listener Hi there, I‚Äôm Sanjay üëã!\nAbout me üî≠ Working: Cloud Developer working on Reactive Spring Boot, Kafka, Cassandra, Microservices, AWS. üñ•Ô∏è Interests: I love building cool software and systems using Spring Boot, Kotlin and Go üå± Learning: Go | Scala | Design Patterns üí¨ Ask me about: Java | Reactive Spring | AWS üßë‚Äçü§ù‚Äçüßë Collaboration: I\u0026#39;m looking to collaborate on several projects over here, please check out my GitHub repos Languages, Frameworks and Platforms What is AWS SQS SQS offers a Secure, Durable, and Highly Available Hosted Queue Used to integrate and decouple distributed software systems and components Standard queues support at-least-once message delivery, and FIFO queues support exactly-once message processing and high-throughput mode Offers Dead Letter Queues SQS Concepts w.r.t Lambda Queue Types: Standard and FIFO Visibility timeout: wait time after which message is visible again if not deleted after processing In-Flight messages: messages that are received by the consumer but not deleted Message retention period: 1 minute to 14 days (defaults to 4 days) Delivery delay: 0 seconds to 15 minutes SQS Event Source Mapping: Lambda Service reads items from a SQS \u0026amp; invokes Lambda Function Enable trigger: Enable or disable SQS-Lambda Integration Batch size: number of records to send to the function in each batch. Standard: 10,000(max). FIFO: 10(max) Batch window: wait time (in second) to gather records before invoking the function, applicable for Standard Message Lifecycle SQS Visibility Timeout To avoid message loss, it\u0026#39;s consumers responsibility to delete the message after processing Message remains in queue after it is received, but SQS sets a visibility timeout to prevent other consumer from processing same message again Default visibility timeout is 30 seconds. Can be set between 0 seconds to 12 hours Can be set a Queue level or dynamically changed per message Caution: When using FIFO make sure to use Message GroupId which provides high distribution to avoid blocking processing due to error Note: For Standard queues, the visibility timeout isn\u0026#39;t a guarantee against receiving a message twice. FIFO queues allow the producer or consumer to attempt multiple retries: producers can retry send using deduplicationId and consumers doesn\u0026#39;t receive messages for same message groupId unless deleted or timed-out Lambda Scaling Standard Queues: Lambda uses long polling \u0026amp; reads up to 5 batches to invoke your function. Lambda increases the number of processes that reads batches by up to 60 more instances per minute. The max no. of batches that an Event Source Mapping can process simultaneously is 1,000. FIFO queues: Lambda sends messages to your function in the order that it receives them and ensures that messages in the same group are delivered to Lambda in order. Lambda sorts the messages into groups and sends only one batch at a time for a group. Your function can scale in concurrency to the number of active message groups. Faster polling scale-up for AWS Lambda Lambda Scaling Diagram here\nSQS Message Event in Lambda Function - Standard { \u0026#34;Records\u0026#34;: [ { \u0026#34;messageId\u0026#34;: \u0026#34;059f36b4-87a3-44ab-83d2-661975830a7d\u0026#34;, \u0026#34;receiptHandle\u0026#34;: \u0026#34;AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Test message.\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;ApproximateReceiveCount\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;SentTimestamp\u0026#34;: \u0026#34;1545082649183\u0026#34;, \u0026#34;SenderId\u0026#34;: \u0026#34;AIDAIENQZJOLO23YVJ4VO\u0026#34;, \u0026#34;ApproximateFirstReceiveTimestamp\u0026#34;: \u0026#34;1545082649185\u0026#34; }, \u0026#34;messageAttributes\u0026#34;: {}, \u0026#34;md5OfBody\u0026#34;: \u0026#34;e4e68fb7bd0e697a0ae8f1bb342846b3\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;aws:sqs\u0026#34;, \u0026#34;eventSourceARN\u0026#34;: \u0026#34;arn:aws:sqs:us-east-2:123456789012:my-queue\u0026#34;, \u0026#34;awsRegion\u0026#34;: \u0026#34;us-east-2\u0026#34; }, ... ] } SQS Message Event in Lambda Function - FIFO { \u0026#34;Records\u0026#34;: [ { \u0026#34;messageId\u0026#34;: \u0026#34;11d6ee51-4cc7-4302-9e22-7cd8afdaadf5\u0026#34;, \u0026#34;receiptHandle\u0026#34;: \u0026#34;AQEBBX8nesZEXmkhsmZeyIE8iQAMig7qw...\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Test message.\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;ApproximateReceiveCount\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;SentTimestamp\u0026#34;: \u0026#34;1573251510774\u0026#34;, \u0026#34;SequenceNumber\u0026#34;: \u0026#34;18849496460467696128\u0026#34;, \u0026#34;MessageGroupId\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;SenderId\u0026#34;: \u0026#34;AIDAIO23YVJENQZJOL4VO\u0026#34;, \u0026#34;MessageDeduplicationId\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;ApproximateFirstReceiveTimestamp\u0026#34;: \u0026#34;1573251510774\u0026#34; }, \u0026#34;messageAttributes\u0026#34;: {}, \u0026#34;md5OfBody\u0026#34;: \u0026#34;e4e68fb7bd0e697a0ae8f1bb342846b3\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;aws:sqs\u0026#34;, \u0026#34;eventSourceARN\u0026#34;: \u0026#34;arn:aws:sqs:us-east-2:123456789012:fifo.fifo\u0026#34;, \u0026#34;awsRegion\u0026#34;: \u0026#34;us-east-2\u0026#34; } ] } Code Questions? ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c7a6cbe914c6b58c25cb6bc75fb1fa0a","permalink":"https://rawsanj.dev/slides/blazing-fast-sqs-listener/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/blazing-fast-sqs-listener/","section":"slides","summary":"A High Performance, Resilient and Cost Effective AWS SQS Listener","tags":["aws","sqs","reactive","java","container","resiliency"],"title":"Blazing Fast SQS Listener","type":"slides"}]